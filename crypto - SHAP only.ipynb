{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45d06aed-c503-4b4b-b46e-aa5af45d2680",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-25 16:34:27.141099: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-05-25 16:34:27.141160: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-05-25 16:34:27.142007: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.15.0\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)  # should be 2.15.0\n",
    "print(tf.config.list_physical_devices('GPU'))  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94a8e602-9b08-46b4-80db-63ecd966776e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f5eecf-0560-4eff-8546-eb5e3bf2f687",
   "metadata": {},
   "source": [
    "### ðŸ§½ Warning Suppression\n",
    "\n",
    "To maintain a clean output and avoid cluttering the notebook with non-critical warnings (e.g., future deprecations), we suppress all warnings using Python's built-in `warnings` module:\n",
    "\n",
    "```python\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5fbd10e6-4515-49e1-871d-902f1ee5d6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a19cdf4d-e3e7-496f-8509-948431d149b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utilities' from '/home/jovyan/files/utilities.py'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import utilities  \n",
    "\n",
    "importlib.reload(utilities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f1db9ea-992b-4b03-af1d-c8a6922cf06b",
   "metadata": {
    "id": "7f1db9ea-992b-4b03-af1d-c8a6922cf06b"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import json\n",
    "from datetime import datetime,timedelta\n",
    "import requests\n",
    "import ta\n",
    "import base64\n",
    "from cryptography.hazmat.primitives import serialization\n",
    "from cryptography.hazmat.backends import default_backend\n",
    "from snowflake.sqlalchemy import URL\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy import text\n",
    "import networkx as nx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f10b363",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0f10b363",
    "outputId": "d50ecd1d-fccd-40f3-c0c1-34dd0ef4cafa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "310d4bfb-2c6c-4822-ace1-e6a5adee1042",
   "metadata": {},
   "source": [
    "# Snowflake Connection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "438709e3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "438709e3",
    "outputId": "e154e80c-cc4c-40b1-b91e-7271d0bc6978"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Snowflake connected: ('CRYPTO_USER', 'CRYPTO_ROLE', datetime.datetime(2025, 5, 25, 9, 34, 32, 53000, tzinfo=<DstTzInfo 'America/Los_Angeles' PDT-1 day, 17:00:00 DST>))\n"
     ]
    }
   ],
   "source": [
    "with open(os.getenv(\"PRIVATE_KEY_PATH\"), \"rb\") as key_file:\n",
    "    private_key = serialization.load_pem_private_key(\n",
    "        key_file.read(),\n",
    "        password=None,\n",
    "        backend=default_backend()\n",
    "    )\n",
    "\n",
    "private_key_pkcs8 = base64.b64encode(\n",
    "    private_key.private_bytes(\n",
    "        encoding=serialization.Encoding.DER,\n",
    "        format=serialization.PrivateFormat.PKCS8,\n",
    "        encryption_algorithm=serialization.NoEncryption()\n",
    "    )\n",
    ").decode(\"utf-8\")  # âœ… base64 string, not bytes!\n",
    "\n",
    "engine = create_engine(URL(\n",
    "    account=os.getenv(\"SNOWFLAKE_ACCOUNT\"),\n",
    "    user=os.getenv(\"SNOWFLAKE_USER\"),\n",
    "    private_key=private_key_pkcs8,\n",
    "    warehouse=os.getenv(\"SNOWFLAKE_WAREHOUSE\"),\n",
    "    database=os.getenv(\"SNOWFLAKE_DATABASE\"),\n",
    "    schema=os.getenv(\"SNOWFLAKE_SCHEMA\"),\n",
    "    role=os.getenv(\"SNOWFLAKE_ROLE\")\n",
    "))\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    result = conn.execute(text(\"SELECT CURRENT_USER(), CURRENT_ROLE(), CURRENT_TIMESTAMP();\"))\n",
    "    for row in result:\n",
    "        print(\"âœ… Snowflake connected:\", row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8003286e-cc1a-44b3-8bfb-c5da0ea162a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "execution_time = datetime.now().strftime(\"%Y%m%d%H%M%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba52374b-6cbf-429b-a0eb-465487988a24",
   "metadata": {},
   "source": [
    "# Reading assets file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28e2dc6f-6a49-419e-b63f-fceef275cef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "top100 = pd.read_csv('Assets_Categorized.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "277cc975-af83-464d-97ef-7bc4b23143e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "top100['staging'] = '@cryptodatasource'\n",
    "top100.drop(columns=['realticker'],inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f9b4db-482f-4099-a87f-e7d0409087e3",
   "metadata": {},
   "source": [
    "### ðŸ—‚ï¸ Incremental Data Ingestion from Yahoo Finance\n",
    "\n",
    "This section ensures that price data for the top 100 tickers is **up-to-date**, downloading only the missing historical records and storing them into a Snowflake staging area.\n",
    "\n",
    "#### **Logic Breakdown**\n",
    "- **Latest Date Check**: For each ticker, the script queries the latest available date from the `VW_CRYPTO` view in Snowflake.\n",
    "- **Smart Start Date**: If no data exists, it defaults to `2019-01-01`. Otherwise, it starts from the next day after the most recent entry.\n",
    "- **Skip Up-to-Date Tickers**: If the latest date is today or later, the ticker is skipped to avoid redundant downloads.\n",
    "- **Download Missing Data**: For all other cases, the `download_yahoo_to_stage()` utility fetches historical daily prices from Yahoo Finance and stages them.\n",
    "\n",
    "#### **Why This Matters**\n",
    "- Ensures efficient **delta loading** â€” no unnecessary API calls or overwrites.\n",
    "- Maintains **data freshness** for modeling and clustering without full reprocessing.\n",
    "- Reduces compute costs and network traffic by avoiding full dataset reloads.\n",
    "\n",
    "> âš™ï¸ This incremental ingestion design is perfect for **automated daily jobs** (e.g., via Airflow or dbt) and supports long-term project scalability.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3519776f-0da5-4fe2-8b8c-f2bb0a48edf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from utilities import download_yahoo_to_stage\n",
    "\n",
    "# now = datetime(datetime.now().year,datetime.now().month,datetime.now().day)\n",
    "# start_date = datetime(2019, 1, 1)\n",
    "\n",
    "# for index, row in top100.iterrows():\n",
    "#     query = text(\"SELECT coalesce(dateadd(day,1,MAX(date)),'2019-01-01') as date FROM PUBLIC.VW_CRYPTO WHERE ticker = :ticker \")\n",
    "#     df_date = pd.read_sql(query, con=engine, params={\"ticker\": row['ticker']})\n",
    "#     start_date = pd.to_datetime(df_date['date'].iloc[0])\n",
    "     \n",
    "#     if start_date > now:\n",
    "#         print(f\"âœ… {row['ticker']}: Up to date â€” skipping download.\")\n",
    "#     else:\n",
    "#         # Download only whatâ€™s missing\n",
    "#         download_yahoo_to_stage(\n",
    "#             ticker=row['ticker'],\n",
    "#             private_key=private_key,\n",
    "#             stage_area=row['staging'],\n",
    "#             interval=\"1d\",\n",
    "#             start=start_date,\n",
    "#             time=\"12:00 AM\",\n",
    "#             execution_time=execution_time\n",
    "#         )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c96555b-1f99-4e1b-9cb6-4d27f1a81ee5",
   "metadata": {},
   "source": [
    "### ðŸ§¹ Data Loading & Cleaning: OHLCV Time Series\n",
    "\n",
    "This step loads the OHLCV (Open, High, Low, Close, Volume) price data for crypto tickers from Snowflake and applies a multi-step cleaning process to ensure consistency across the dataset.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Step 1: Load & Filter**\n",
    "- SQL query pulls price data from `VW_CRYPTO` starting from `2020-01-01`.\n",
    "- Filters out **stablecoins** (non-volatile by design) to focus on more predictive assets.\n",
    "- Merges with the `top100` metadata to bring in staging/category info.\n",
    "\n",
    "#### **Step 2: Missing Value Handling**\n",
    "Each OHLCV column is cleaned with a **multi-stage imputation** strategy:\n",
    "1. **Forward-fill** (fill with previous known value)\n",
    "2. **Backward-fill** (fill with next known value)\n",
    "3. **Fill with per-ticker mean** if still missing\n",
    "\n",
    "This preserves temporal continuity and avoids dropping valuable rows due to sparsity.\n",
    "\n",
    "#### **Step 3: Pivot to Close Price Matrix**\n",
    "- A matrix of close prices is created (`price_df`), with:\n",
    "  - **Rows** = Dates\n",
    "  - **Columns** = Tickers\n",
    "  - **Values** = Closing prices\n",
    "\n",
    "#### **Step 4: Final Cleanup**\n",
    "- Any remaining NaNs in `price_df` (likely isolated values) are filled with the **average close price** for that ticker.\n",
    "- A final NaN check is performed and printed to validate the dataset is ready for analysis.\n",
    "\n",
    "---\n",
    "\n",
    "> ðŸ“Œ This data wrangling stage ensures a **complete and consistent** dataset â€” a critical foundation for accurate clustering, modeling, and evaluation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bc80c32c-e6ab-4019-9dda-0c968b5462ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Loaded data for tickers: 142\n",
      "ðŸ§¹ Still NaNs in `data` (should be 0):\n",
      "Series([], dtype: int64)\n",
      "ðŸ§¹ Still NaN per ticker (should be 0):\n",
      "Series([], dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import text\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Step 1: Load and merge\n",
    "query = text(\"\"\"\n",
    "    SELECT DISTINCT date, open,high,low,close, volume, ticker\n",
    "    FROM PUBLIC.VW_CRYPTO\n",
    "    WHERE date >= '2020-01-01'\n",
    "    and ticker in ( select distinct ticker from vw_crypto where date <='2020-01-01')\n",
    "    ORDER BY ticker, date\n",
    "\"\"\")\n",
    "data = pd.read_sql(query, con=engine)\n",
    "data.drop_duplicates(['date', 'ticker'], keep='last', inplace=True)\n",
    "\n",
    "data = pd.merge(data, top100, on='ticker', how='left')\n",
    "data = data[data['category'] != 'Stablecoin']\n",
    "\n",
    "print(\"âœ… Loaded data for tickers:\", data['ticker'].nunique())\n",
    "\n",
    "\n",
    "ohlcv_cols = ['open', 'high', 'low', 'close', 'volume']\n",
    "data = data.sort_values(by=['ticker', 'date'])\n",
    "\n",
    "for col in ohlcv_cols:\n",
    "    # Fill forward, then backward, then with mean (per ticker)\n",
    "    data[col] = (\n",
    "        data.groupby('ticker')[col]\n",
    "        .apply(lambda grp: grp.ffill().bfill().fillna(grp.mean()))\n",
    "        .reset_index(level=0, drop=True)\n",
    "    )\n",
    "\n",
    "nan_summary = data[ohlcv_cols].isna().sum()\n",
    "print(\"ðŸ§¹ Still NaNs in `data` (should be 0):\")\n",
    "print(nan_summary[nan_summary > 0])\n",
    "\n",
    "\n",
    "# Step 2: Pivot close prices\n",
    "price_df = data.pivot(index='date', columns='ticker', values='close')\n",
    "\n",
    "# b. Fill remaining NaNs with the average of the column\n",
    "price_df = price_df.apply(lambda col: col.fillna(col.mean()), axis=0)\n",
    "\n",
    "# Step 4: Optional check\n",
    "nan_summary = price_df.isna().sum()\n",
    "print(\"ðŸ§¹ Still NaN per ticker (should be 0):\")\n",
    "print(nan_summary[nan_summary > 0])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "18de3531-6b0f-4176-aa8b-4ec9e11456a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>ticker</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>ADA-USD</th>\n",
       "      <th>ADBE</th>\n",
       "      <th>ADI</th>\n",
       "      <th>ADP</th>\n",
       "      <th>ADSK</th>\n",
       "      <th>AEP</th>\n",
       "      <th>ALGO-USD</th>\n",
       "      <th>AMAT</th>\n",
       "      <th>AMD</th>\n",
       "      <th>...</th>\n",
       "      <th>XEL</th>\n",
       "      <th>XLM-USD</th>\n",
       "      <th>XMR-USD</th>\n",
       "      <th>XRP-USD</th>\n",
       "      <th>XTZ-USD</th>\n",
       "      <th>ZEC-USD</th>\n",
       "      <th>ZS</th>\n",
       "      <th>^GSPC</th>\n",
       "      <th>^NDX</th>\n",
       "      <th>^VIX</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-01-01</th>\n",
       "      <td>156.905111</td>\n",
       "      <td>0.033458</td>\n",
       "      <td>468.000236</td>\n",
       "      <td>163.302150</td>\n",
       "      <td>210.340759</td>\n",
       "      <td>240.050804</td>\n",
       "      <td>80.751228</td>\n",
       "      <td>0.219938</td>\n",
       "      <td>126.195807</td>\n",
       "      <td>103.856844</td>\n",
       "      <td>...</td>\n",
       "      <td>60.089335</td>\n",
       "      <td>0.045451</td>\n",
       "      <td>45.753544</td>\n",
       "      <td>0.192667</td>\n",
       "      <td>1.370210</td>\n",
       "      <td>28.050165</td>\n",
       "      <td>175.537954</td>\n",
       "      <td>4368.310738</td>\n",
       "      <td>14608.588987</td>\n",
       "      <td>21.44444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-02</th>\n",
       "      <td>72.620834</td>\n",
       "      <td>0.032751</td>\n",
       "      <td>334.429993</td>\n",
       "      <td>109.436218</td>\n",
       "      <td>152.393860</td>\n",
       "      <td>187.830002</td>\n",
       "      <td>76.578613</td>\n",
       "      <td>0.213518</td>\n",
       "      <td>59.056660</td>\n",
       "      <td>49.099998</td>\n",
       "      <td>...</td>\n",
       "      <td>53.112019</td>\n",
       "      <td>0.044112</td>\n",
       "      <td>45.749470</td>\n",
       "      <td>0.188043</td>\n",
       "      <td>1.241036</td>\n",
       "      <td>27.118073</td>\n",
       "      <td>47.330002</td>\n",
       "      <td>3257.850098</td>\n",
       "      <td>8872.219727</td>\n",
       "      <td>12.47000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-03</th>\n",
       "      <td>71.914803</td>\n",
       "      <td>0.034180</td>\n",
       "      <td>331.809998</td>\n",
       "      <td>107.509766</td>\n",
       "      <td>152.071762</td>\n",
       "      <td>184.949997</td>\n",
       "      <td>76.496651</td>\n",
       "      <td>0.228098</td>\n",
       "      <td>58.116684</td>\n",
       "      <td>48.599998</td>\n",
       "      <td>...</td>\n",
       "      <td>53.367439</td>\n",
       "      <td>0.045234</td>\n",
       "      <td>51.092037</td>\n",
       "      <td>0.193521</td>\n",
       "      <td>1.282225</td>\n",
       "      <td>28.618681</td>\n",
       "      <td>47.380001</td>\n",
       "      <td>3234.850098</td>\n",
       "      <td>8793.900391</td>\n",
       "      <td>14.02000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-04</th>\n",
       "      <td>156.905111</td>\n",
       "      <td>0.034595</td>\n",
       "      <td>468.000236</td>\n",
       "      <td>163.302150</td>\n",
       "      <td>210.340759</td>\n",
       "      <td>240.050804</td>\n",
       "      <td>80.751228</td>\n",
       "      <td>0.236382</td>\n",
       "      <td>126.195807</td>\n",
       "      <td>103.856844</td>\n",
       "      <td>...</td>\n",
       "      <td>60.089335</td>\n",
       "      <td>0.046272</td>\n",
       "      <td>50.536694</td>\n",
       "      <td>0.194355</td>\n",
       "      <td>1.261942</td>\n",
       "      <td>30.238680</td>\n",
       "      <td>175.537954</td>\n",
       "      <td>4368.310738</td>\n",
       "      <td>14608.588987</td>\n",
       "      <td>21.44444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-05</th>\n",
       "      <td>156.905111</td>\n",
       "      <td>0.034721</td>\n",
       "      <td>468.000236</td>\n",
       "      <td>163.302150</td>\n",
       "      <td>210.340759</td>\n",
       "      <td>240.050804</td>\n",
       "      <td>80.751228</td>\n",
       "      <td>0.231657</td>\n",
       "      <td>126.195807</td>\n",
       "      <td>103.856844</td>\n",
       "      <td>...</td>\n",
       "      <td>60.089335</td>\n",
       "      <td>0.045359</td>\n",
       "      <td>54.096893</td>\n",
       "      <td>0.195537</td>\n",
       "      <td>1.263569</td>\n",
       "      <td>31.021275</td>\n",
       "      <td>175.537954</td>\n",
       "      <td>4368.310738</td>\n",
       "      <td>14608.588987</td>\n",
       "      <td>21.44444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 142 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "ticker            AAPL   ADA-USD        ADBE         ADI         ADP  \\\n",
       "date                                                                   \n",
       "2020-01-01  156.905111  0.033458  468.000236  163.302150  210.340759   \n",
       "2020-01-02   72.620834  0.032751  334.429993  109.436218  152.393860   \n",
       "2020-01-03   71.914803  0.034180  331.809998  107.509766  152.071762   \n",
       "2020-01-04  156.905111  0.034595  468.000236  163.302150  210.340759   \n",
       "2020-01-05  156.905111  0.034721  468.000236  163.302150  210.340759   \n",
       "\n",
       "ticker            ADSK        AEP  ALGO-USD        AMAT         AMD  ...  \\\n",
       "date                                                                 ...   \n",
       "2020-01-01  240.050804  80.751228  0.219938  126.195807  103.856844  ...   \n",
       "2020-01-02  187.830002  76.578613  0.213518   59.056660   49.099998  ...   \n",
       "2020-01-03  184.949997  76.496651  0.228098   58.116684   48.599998  ...   \n",
       "2020-01-04  240.050804  80.751228  0.236382  126.195807  103.856844  ...   \n",
       "2020-01-05  240.050804  80.751228  0.231657  126.195807  103.856844  ...   \n",
       "\n",
       "ticker            XEL   XLM-USD    XMR-USD   XRP-USD   XTZ-USD    ZEC-USD  \\\n",
       "date                                                                        \n",
       "2020-01-01  60.089335  0.045451  45.753544  0.192667  1.370210  28.050165   \n",
       "2020-01-02  53.112019  0.044112  45.749470  0.188043  1.241036  27.118073   \n",
       "2020-01-03  53.367439  0.045234  51.092037  0.193521  1.282225  28.618681   \n",
       "2020-01-04  60.089335  0.046272  50.536694  0.194355  1.261942  30.238680   \n",
       "2020-01-05  60.089335  0.045359  54.096893  0.195537  1.263569  31.021275   \n",
       "\n",
       "ticker              ZS        ^GSPC          ^NDX      ^VIX  \n",
       "date                                                         \n",
       "2020-01-01  175.537954  4368.310738  14608.588987  21.44444  \n",
       "2020-01-02   47.330002  3257.850098   8872.219727  12.47000  \n",
       "2020-01-03   47.380001  3234.850098   8793.900391  14.02000  \n",
       "2020-01-04  175.537954  4368.310738  14608.588987  21.44444  \n",
       "2020-01-05  175.537954  4368.310738  14608.588987  21.44444  \n",
       "\n",
       "[5 rows x 142 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6faa15b0-3592-4695-8ad8-1e6c1c378749",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>ticker</th>\n",
       "      <th>name</th>\n",
       "      <th>category</th>\n",
       "      <th>market</th>\n",
       "      <th>staging</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46100</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>7194.892090</td>\n",
       "      <td>7254.330566</td>\n",
       "      <td>7174.944336</td>\n",
       "      <td>7200.174316</td>\n",
       "      <td>1.856566e+10</td>\n",
       "      <td>BTC-USD</td>\n",
       "      <td>Bitcoin</td>\n",
       "      <td>Layer 1</td>\n",
       "      <td>Crypto</td>\n",
       "      <td>@cryptodatasource</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46101</th>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>7202.551270</td>\n",
       "      <td>7212.155273</td>\n",
       "      <td>6935.270020</td>\n",
       "      <td>6985.470215</td>\n",
       "      <td>2.080208e+10</td>\n",
       "      <td>BTC-USD</td>\n",
       "      <td>Bitcoin</td>\n",
       "      <td>Layer 1</td>\n",
       "      <td>Crypto</td>\n",
       "      <td>@cryptodatasource</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46102</th>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>6984.428711</td>\n",
       "      <td>7413.715332</td>\n",
       "      <td>6914.996094</td>\n",
       "      <td>7344.884277</td>\n",
       "      <td>2.811148e+10</td>\n",
       "      <td>BTC-USD</td>\n",
       "      <td>Bitcoin</td>\n",
       "      <td>Layer 1</td>\n",
       "      <td>Crypto</td>\n",
       "      <td>@cryptodatasource</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46103</th>\n",
       "      <td>2020-01-04</td>\n",
       "      <td>7345.375488</td>\n",
       "      <td>7427.385742</td>\n",
       "      <td>7309.514160</td>\n",
       "      <td>7410.656738</td>\n",
       "      <td>1.844427e+10</td>\n",
       "      <td>BTC-USD</td>\n",
       "      <td>Bitcoin</td>\n",
       "      <td>Layer 1</td>\n",
       "      <td>Crypto</td>\n",
       "      <td>@cryptodatasource</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46104</th>\n",
       "      <td>2020-01-05</td>\n",
       "      <td>7410.451660</td>\n",
       "      <td>7544.497070</td>\n",
       "      <td>7400.535645</td>\n",
       "      <td>7411.317383</td>\n",
       "      <td>1.972507e+10</td>\n",
       "      <td>BTC-USD</td>\n",
       "      <td>Bitcoin</td>\n",
       "      <td>Layer 1</td>\n",
       "      <td>Crypto</td>\n",
       "      <td>@cryptodatasource</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            date         open         high          low        close  \\\n",
       "46100 2020-01-01  7194.892090  7254.330566  7174.944336  7200.174316   \n",
       "46101 2020-01-02  7202.551270  7212.155273  6935.270020  6985.470215   \n",
       "46102 2020-01-03  6984.428711  7413.715332  6914.996094  7344.884277   \n",
       "46103 2020-01-04  7345.375488  7427.385742  7309.514160  7410.656738   \n",
       "46104 2020-01-05  7410.451660  7544.497070  7400.535645  7411.317383   \n",
       "\n",
       "             volume   ticker     name category  market            staging  \n",
       "46100  1.856566e+10  BTC-USD  Bitcoin  Layer 1  Crypto  @cryptodatasource  \n",
       "46101  2.080208e+10  BTC-USD  Bitcoin  Layer 1  Crypto  @cryptodatasource  \n",
       "46102  2.811148e+10  BTC-USD  Bitcoin  Layer 1  Crypto  @cryptodatasource  \n",
       "46103  1.844427e+10  BTC-USD  Bitcoin  Layer 1  Crypto  @cryptodatasource  \n",
       "46104  1.972507e+10  BTC-USD  Bitcoin  Layer 1  Crypto  @cryptodatasource  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "btc_df = data[data['ticker'] == 'BTC-USD'].copy()\n",
    "btc_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "70aba67f-74a6-49ac-847d-f2f69611a14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Prepare price delta as target -----\n",
    "btc_df['target'] = btc_df['close'].shift(-1) - btc_df['close']\n",
    "btc_features = btc_df.set_index('date')[['target']].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "29cec070-e98c-41d0-af9e-aef2a6a69bbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-01-01</th>\n",
       "      <td>-214.704102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-02</th>\n",
       "      <td>359.414062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-03</th>\n",
       "      <td>65.772461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-04</th>\n",
       "      <td>0.660645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-05</th>\n",
       "      <td>357.901855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-20</th>\n",
       "      <td>2886.992188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-21</th>\n",
       "      <td>1995.203125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-22</th>\n",
       "      <td>-4385.484375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-23</th>\n",
       "      <td>503.359375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-24</th>\n",
       "      <td>-96.453125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1971 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 target\n",
       "date                   \n",
       "2020-01-01  -214.704102\n",
       "2020-01-02   359.414062\n",
       "2020-01-03    65.772461\n",
       "2020-01-04     0.660645\n",
       "2020-01-05   357.901855\n",
       "...                 ...\n",
       "2025-05-20  2886.992188\n",
       "2025-05-21  1995.203125\n",
       "2025-05-22 -4385.484375\n",
       "2025-05-23   503.359375\n",
       "2025-05-24   -96.453125\n",
       "\n",
       "[1971 rows x 1 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "btc_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c332787b-9aa3-41ba-b03e-03dc89d7fd87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>ticker</th>\n",
       "      <th>name</th>\n",
       "      <th>category</th>\n",
       "      <th>market</th>\n",
       "      <th>staging</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>71.627084</td>\n",
       "      <td>72.681281</td>\n",
       "      <td>71.373211</td>\n",
       "      <td>72.620834</td>\n",
       "      <td>135480400.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Apple Inc.</td>\n",
       "      <td>Nasdaq-100</td>\n",
       "      <td>Stock</td>\n",
       "      <td>@cryptodatasource</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>71.847102</td>\n",
       "      <td>72.676431</td>\n",
       "      <td>71.689942</td>\n",
       "      <td>71.914803</td>\n",
       "      <td>146322800.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Apple Inc.</td>\n",
       "      <td>Nasdaq-100</td>\n",
       "      <td>Stock</td>\n",
       "      <td>@cryptodatasource</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-06</td>\n",
       "      <td>71.034709</td>\n",
       "      <td>72.526533</td>\n",
       "      <td>70.783248</td>\n",
       "      <td>72.487846</td>\n",
       "      <td>118387200.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Apple Inc.</td>\n",
       "      <td>Nasdaq-100</td>\n",
       "      <td>Stock</td>\n",
       "      <td>@cryptodatasource</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-07</td>\n",
       "      <td>72.497522</td>\n",
       "      <td>72.753816</td>\n",
       "      <td>71.926907</td>\n",
       "      <td>72.146935</td>\n",
       "      <td>108872000.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Apple Inc.</td>\n",
       "      <td>Nasdaq-100</td>\n",
       "      <td>Stock</td>\n",
       "      <td>@cryptodatasource</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-08</td>\n",
       "      <td>71.849540</td>\n",
       "      <td>73.609752</td>\n",
       "      <td>71.849540</td>\n",
       "      <td>73.307518</td>\n",
       "      <td>132079200.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Apple Inc.</td>\n",
       "      <td>Nasdaq-100</td>\n",
       "      <td>Stock</td>\n",
       "      <td>@cryptodatasource</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date       open       high        low      close       volume ticker  \\\n",
       "0 2020-01-02  71.627084  72.681281  71.373211  72.620834  135480400.0   AAPL   \n",
       "1 2020-01-03  71.847102  72.676431  71.689942  71.914803  146322800.0   AAPL   \n",
       "2 2020-01-06  71.034709  72.526533  70.783248  72.487846  118387200.0   AAPL   \n",
       "3 2020-01-07  72.497522  72.753816  71.926907  72.146935  108872000.0   AAPL   \n",
       "4 2020-01-08  71.849540  73.609752  71.849540  73.307518  132079200.0   AAPL   \n",
       "\n",
       "         name    category market            staging  \n",
       "0  Apple Inc.  Nasdaq-100  Stock  @cryptodatasource  \n",
       "1  Apple Inc.  Nasdaq-100  Stock  @cryptodatasource  \n",
       "2  Apple Inc.  Nasdaq-100  Stock  @cryptodatasource  \n",
       "3  Apple Inc.  Nasdaq-100  Stock  @cryptodatasource  \n",
       "4  Apple Inc.  Nasdaq-100  Stock  @cryptodatasource  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "be1c79f0-e67d-4da3-8464-38b993e1f905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with peer prices\n",
    "final_df = btc_features.join(price_df, how='inner').dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d815d91c-9f60-4c39-bb9f-7a2dce5931fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>ADA-USD</th>\n",
       "      <th>ADBE</th>\n",
       "      <th>ADI</th>\n",
       "      <th>ADP</th>\n",
       "      <th>ADSK</th>\n",
       "      <th>AEP</th>\n",
       "      <th>ALGO-USD</th>\n",
       "      <th>AMAT</th>\n",
       "      <th>...</th>\n",
       "      <th>XEL</th>\n",
       "      <th>XLM-USD</th>\n",
       "      <th>XMR-USD</th>\n",
       "      <th>XRP-USD</th>\n",
       "      <th>XTZ-USD</th>\n",
       "      <th>ZEC-USD</th>\n",
       "      <th>ZS</th>\n",
       "      <th>^GSPC</th>\n",
       "      <th>^NDX</th>\n",
       "      <th>^VIX</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-01-01</th>\n",
       "      <td>-214.704102</td>\n",
       "      <td>156.905111</td>\n",
       "      <td>0.033458</td>\n",
       "      <td>468.000236</td>\n",
       "      <td>163.302150</td>\n",
       "      <td>210.340759</td>\n",
       "      <td>240.050804</td>\n",
       "      <td>80.751228</td>\n",
       "      <td>0.219938</td>\n",
       "      <td>126.195807</td>\n",
       "      <td>...</td>\n",
       "      <td>60.089335</td>\n",
       "      <td>0.045451</td>\n",
       "      <td>45.753544</td>\n",
       "      <td>0.192667</td>\n",
       "      <td>1.370210</td>\n",
       "      <td>28.050165</td>\n",
       "      <td>175.537954</td>\n",
       "      <td>4368.310738</td>\n",
       "      <td>14608.588987</td>\n",
       "      <td>21.44444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-02</th>\n",
       "      <td>359.414062</td>\n",
       "      <td>72.620834</td>\n",
       "      <td>0.032751</td>\n",
       "      <td>334.429993</td>\n",
       "      <td>109.436218</td>\n",
       "      <td>152.393860</td>\n",
       "      <td>187.830002</td>\n",
       "      <td>76.578613</td>\n",
       "      <td>0.213518</td>\n",
       "      <td>59.056660</td>\n",
       "      <td>...</td>\n",
       "      <td>53.112019</td>\n",
       "      <td>0.044112</td>\n",
       "      <td>45.749470</td>\n",
       "      <td>0.188043</td>\n",
       "      <td>1.241036</td>\n",
       "      <td>27.118073</td>\n",
       "      <td>47.330002</td>\n",
       "      <td>3257.850098</td>\n",
       "      <td>8872.219727</td>\n",
       "      <td>12.47000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-03</th>\n",
       "      <td>65.772461</td>\n",
       "      <td>71.914803</td>\n",
       "      <td>0.034180</td>\n",
       "      <td>331.809998</td>\n",
       "      <td>107.509766</td>\n",
       "      <td>152.071762</td>\n",
       "      <td>184.949997</td>\n",
       "      <td>76.496651</td>\n",
       "      <td>0.228098</td>\n",
       "      <td>58.116684</td>\n",
       "      <td>...</td>\n",
       "      <td>53.367439</td>\n",
       "      <td>0.045234</td>\n",
       "      <td>51.092037</td>\n",
       "      <td>0.193521</td>\n",
       "      <td>1.282225</td>\n",
       "      <td>28.618681</td>\n",
       "      <td>47.380001</td>\n",
       "      <td>3234.850098</td>\n",
       "      <td>8793.900391</td>\n",
       "      <td>14.02000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-04</th>\n",
       "      <td>0.660645</td>\n",
       "      <td>156.905111</td>\n",
       "      <td>0.034595</td>\n",
       "      <td>468.000236</td>\n",
       "      <td>163.302150</td>\n",
       "      <td>210.340759</td>\n",
       "      <td>240.050804</td>\n",
       "      <td>80.751228</td>\n",
       "      <td>0.236382</td>\n",
       "      <td>126.195807</td>\n",
       "      <td>...</td>\n",
       "      <td>60.089335</td>\n",
       "      <td>0.046272</td>\n",
       "      <td>50.536694</td>\n",
       "      <td>0.194355</td>\n",
       "      <td>1.261942</td>\n",
       "      <td>30.238680</td>\n",
       "      <td>175.537954</td>\n",
       "      <td>4368.310738</td>\n",
       "      <td>14608.588987</td>\n",
       "      <td>21.44444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-05</th>\n",
       "      <td>357.901855</td>\n",
       "      <td>156.905111</td>\n",
       "      <td>0.034721</td>\n",
       "      <td>468.000236</td>\n",
       "      <td>163.302150</td>\n",
       "      <td>210.340759</td>\n",
       "      <td>240.050804</td>\n",
       "      <td>80.751228</td>\n",
       "      <td>0.231657</td>\n",
       "      <td>126.195807</td>\n",
       "      <td>...</td>\n",
       "      <td>60.089335</td>\n",
       "      <td>0.045359</td>\n",
       "      <td>54.096893</td>\n",
       "      <td>0.195537</td>\n",
       "      <td>1.263569</td>\n",
       "      <td>31.021275</td>\n",
       "      <td>175.537954</td>\n",
       "      <td>4368.310738</td>\n",
       "      <td>14608.588987</td>\n",
       "      <td>21.44444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 143 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                target        AAPL   ADA-USD        ADBE         ADI  \\\n",
       "date                                                                   \n",
       "2020-01-01 -214.704102  156.905111  0.033458  468.000236  163.302150   \n",
       "2020-01-02  359.414062   72.620834  0.032751  334.429993  109.436218   \n",
       "2020-01-03   65.772461   71.914803  0.034180  331.809998  107.509766   \n",
       "2020-01-04    0.660645  156.905111  0.034595  468.000236  163.302150   \n",
       "2020-01-05  357.901855  156.905111  0.034721  468.000236  163.302150   \n",
       "\n",
       "                   ADP        ADSK        AEP  ALGO-USD        AMAT  ...  \\\n",
       "date                                                                 ...   \n",
       "2020-01-01  210.340759  240.050804  80.751228  0.219938  126.195807  ...   \n",
       "2020-01-02  152.393860  187.830002  76.578613  0.213518   59.056660  ...   \n",
       "2020-01-03  152.071762  184.949997  76.496651  0.228098   58.116684  ...   \n",
       "2020-01-04  210.340759  240.050804  80.751228  0.236382  126.195807  ...   \n",
       "2020-01-05  210.340759  240.050804  80.751228  0.231657  126.195807  ...   \n",
       "\n",
       "                  XEL   XLM-USD    XMR-USD   XRP-USD   XTZ-USD    ZEC-USD  \\\n",
       "date                                                                        \n",
       "2020-01-01  60.089335  0.045451  45.753544  0.192667  1.370210  28.050165   \n",
       "2020-01-02  53.112019  0.044112  45.749470  0.188043  1.241036  27.118073   \n",
       "2020-01-03  53.367439  0.045234  51.092037  0.193521  1.282225  28.618681   \n",
       "2020-01-04  60.089335  0.046272  50.536694  0.194355  1.261942  30.238680   \n",
       "2020-01-05  60.089335  0.045359  54.096893  0.195537  1.263569  31.021275   \n",
       "\n",
       "                    ZS        ^GSPC          ^NDX      ^VIX  \n",
       "date                                                         \n",
       "2020-01-01  175.537954  4368.310738  14608.588987  21.44444  \n",
       "2020-01-02   47.330002  3257.850098   8872.219727  12.47000  \n",
       "2020-01-03   47.380001  3234.850098   8793.900391  14.02000  \n",
       "2020-01-04  175.537954  4368.310738  14608.588987  21.44444  \n",
       "2020-01-05  175.537954  4368.310738  14608.588987  21.44444  \n",
       "\n",
       "[5 rows x 143 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9be0c090-2bf6-422f-8217-1b70fbe6d9b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1748190886.824856   20660 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 4s 13ms/step - loss: 0.0146\n",
      "Epoch 2/25\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.0059\n",
      "Epoch 3/25\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.0059\n",
      "Epoch 4/25\n",
      "48/48 [==============================] - 1s 13ms/step - loss: 0.0058\n",
      "Epoch 5/25\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.0057\n",
      "Epoch 6/25\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.0058\n",
      "Epoch 7/25\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.0057\n",
      "Epoch 8/25\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.0058\n",
      "Epoch 9/25\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.0064\n",
      "Epoch 10/25\n",
      "48/48 [==============================] - 1s 12ms/step - loss: 0.0058\n",
      "12/12 [==============================] - 1s 7ms/step - loss: 0.0162\n",
      "âœ… LSTM Test Loss (MSE): 0.0162\n",
      "12/12 [==============================] - 1s 6ms/step\n",
      "\n",
      "ðŸ“‰ RMSE (price): 2085.94\n",
      "ðŸ“ˆ MAE (price): 1481.33\n",
      "ðŸ“Š RÂ² Score (price): 0.9845\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "\n",
    "# Feature/target split\n",
    "feature_cols = final_df.columns.drop('target')\n",
    "X = final_df[feature_cols].values\n",
    "y = final_df['target'].values\n",
    "\n",
    "# Scaling\n",
    "feature_scaler = MinMaxScaler()\n",
    "target_scaler = MinMaxScaler()\n",
    "\n",
    "X_scaled = feature_scaler.fit_transform(X)\n",
    "y_scaled = target_scaler.fit_transform(y.reshape(-1, 1))\n",
    "\n",
    "# ----- Sequence builder -----\n",
    "def create_sequences(X_data, y_data, time_step):\n",
    "    X_seq, y_seq = [], []\n",
    "    for i in range(len(X_data) - time_step):\n",
    "        X_seq.append(X_data[i:i + time_step])\n",
    "        y_seq.append(y_data[i + time_step - 1])  # predict delta for t+1\n",
    "    return np.array(X_seq), np.array(y_seq)\n",
    "\n",
    "time_step = 60\n",
    "X_seq, y_seq = create_sequences(X_scaled, y_scaled, time_step)\n",
    "\n",
    "# Split\n",
    "split = int(len(X_seq) * 0.8)\n",
    "X_train, X_test = X_seq[:split], X_seq[split:]\n",
    "y_train, y_test = y_seq[:split], y_seq[split:]\n",
    "\n",
    "# ----- Model -----\n",
    "model = Sequential([\n",
    "    LSTM(50, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])),\n",
    "    LSTM(50),\n",
    "    Dense(25, activation='relu'),\n",
    "    Dense(1)\n",
    "])\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Train\n",
    "early_stop = EarlyStopping(monitor='loss', patience=5, restore_best_weights=True)\n",
    "model.fit(X_train, y_train, epochs=25, batch_size=32, callbacks=[early_stop])\n",
    "\n",
    "# Evaluate\n",
    "loss = model.evaluate(X_test, y_test)\n",
    "print(f\"âœ… LSTM Test Loss (MSE): {loss:.4f}\")\n",
    "\n",
    "# ----- Inverse Transform & Rebuild Price -----\n",
    "# Predict deltas (scaled -> real)\n",
    "y_pred_scaled = model.predict(X_test)\n",
    "y_pred_delta = target_scaler.inverse_transform(y_pred_scaled)\n",
    "y_test_delta = target_scaler.inverse_transform(y_test.reshape(-1, 1))\n",
    "\n",
    "\n",
    "btc_close = btc_df.set_index('date')['close']\n",
    "btc_close = btc_close.loc[final_df.index]  # Match dates used in final_df\n",
    "btc_close = btc_close.values[time_step - 1:]  # Align with LSTM shift\n",
    "base_prices = btc_close[-len(y_test):]\n",
    "\n",
    "y_pred_price = base_prices + y_pred_delta.flatten()\n",
    "y_test_price = base_prices + y_test_delta.flatten()\n",
    "\n",
    "\n",
    "# ----- Metrics -----\n",
    "rmse = np.sqrt(mean_squared_error(y_test_price, y_pred_price))\n",
    "mae = mean_absolute_error(y_test_price, y_pred_price)\n",
    "r2 = r2_score(y_test_price, y_pred_price)\n",
    "\n",
    "print(f\"\\nðŸ“‰ RMSE (price): {rmse:.2f}\")\n",
    "print(f\"ðŸ“ˆ MAE (price): {mae:.2f}\")\n",
    "print(f\"ðŸ“Š RÂ² Score (price): {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "868e8861-a864-4b7d-a94d-51fb3b7c106a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Running warm-up prediction to initialize GPU...\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "ðŸ”Ž Input shapes:\n",
      " - X_train shape: (1528, 60, 142)\n",
      " - X_test shape: (383, 60, 142)\n",
      "ðŸš€ Warming up model to initialize GPU...\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "âš™ï¸ Trying SHAP DeepExplainer (fastest)...\n",
      "âš ï¸ DeepExplainer failed: in user code:\n",
      "\n",
      "    File \"/usr/local/lib/python3.11/dist-packages/shap/explainers/_deep/deep_tf.py\", line 245, in grad_graph  *\n",
      "        out = self.model(shap_rAnD)\n",
      "    File \"/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler  **\n",
      "        raise e.with_traceback(filtered_tb) from None\n",
      "    File \"/usr/local/lib/python3.11/dist-packages/shap/explainers/_deep/deep_tf.py\", line 394, in custom_grad\n",
      "        out = op_handlers[type_name](self, op, *grads)  # we cut off the shap_ prefix before the lookup\n",
      "    File \"/usr/local/lib/python3.11/dist-packages/shap/explainers/_deep/deep_tf.py\", line 691, in handler\n",
      "        return linearity_with_excluded_handler(input_inds, explainer, op, *grads)\n",
      "    File \"/usr/local/lib/python3.11/dist-packages/shap/explainers/_deep/deep_tf.py\", line 700, in linearity_with_excluded_handler\n",
      "        assert not explainer._variable_inputs(op)[i], str(i) + \"th input to \" + op.name + \" cannot vary!\"\n",
      "    File \"/usr/local/lib/python3.11/dist-packages/shap/explainers/_deep/deep_tf.py\", line 221, in _variable_inputs\n",
      "        out[i] = t.name in self.between_tensors\n",
      "\n",
      "    AttributeError: Exception encountered when calling layer 'lstm' (type LSTM).\n",
      "    \n",
      "    'TFDeep' object has no attribute 'between_tensors'\n",
      "    \n",
      "    Call arguments received by layer 'lstm' (type LSTM):\n",
      "      â€¢ inputs=tf.Tensor(shape=(600, 60, 142), dtype=float32)\n",
      "      â€¢ mask=None\n",
      "      â€¢ training=False\n",
      "      â€¢ initial_state=None\n",
      "\n",
      "ðŸ” Falling back to KernelExplainer (CPU-only)...\n",
      "10/10 [==============================] - 0s 7ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 300 background data samples could cause slower run times. Consider using shap.sample(data, K) or shap.kmeans(data, K) to summarize the background as K samples.\n",
      "  0%|          | 0/150 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 20ms/step\n",
      "938/938 [==============================] - 4s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/150 [00:08<22:09,  8.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 22ms/step\n",
      "938/938 [==============================] - 5s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|â–         | 2/150 [00:17<21:52,  8.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 23ms/step\n",
      "938/938 [==============================] - 5s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|â–         | 3/150 [00:25<20:45,  8.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 17ms/step\n",
      "938/938 [==============================] - 5s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|â–Ž         | 4/150 [00:34<20:35,  8.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 28ms/step\n",
      "938/938 [==============================] - 5s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|â–Ž         | 5/150 [00:42<19:53,  8.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 17ms/step\n",
      "938/938 [==============================] - 5s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|â–         | 6/150 [00:50<19:44,  8.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 18ms/step\n",
      "938/938 [==============================] - 6s 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|â–         | 7/150 [00:59<20:21,  8.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 20ms/step\n",
      "938/938 [==============================] - 5s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|â–Œ         | 8/150 [01:07<20:04,  8.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 19ms/step\n",
      "938/938 [==============================] - 5s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|â–Œ         | 9/150 [01:17<20:33,  8.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 22ms/step\n",
      "938/938 [==============================] - 5s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|â–‹         | 10/150 [01:25<20:01,  8.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|â–‹         | 10/150 [01:38<22:58,  9.84s/it]\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mInternalError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mðŸš€ Running warm-up prediction to initialize GPU...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      4\u001b[39m _ = model.predict(X_train[:\u001b[32m1\u001b[39m])\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[43mexplain_lstm_with_shap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfeature_cols\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfeature_cols\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtime_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m60\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbackground_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m300\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[43msample_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m150\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnsamples\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[43mplot_filename\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mshap_lstm_v1.png\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[43mplot_influence\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mshap_crypto_influence_louvain\u001b[39;49m\u001b[33;43m'\u001b[39;49m\n\u001b[32m     18\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/jovyan/files/utilities.py:796\u001b[39m, in \u001b[36mexplain_lstm_with_shap\u001b[39m\u001b[34m(model, X_train, X_test, feature_cols, time_steps, background_size, sample_size, nsamples, plot_filename, plot_influence)\u001b[39m\n\u001b[32m    793\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m model.predict(X_flat.reshape((X_flat.shape[\u001b[32m0\u001b[39m], time_steps, -\u001b[32m1\u001b[39m)))\n\u001b[32m    795\u001b[39m explainer = shap.KernelExplainer(model_predict, X_background_flat)\n\u001b[32m--> \u001b[39m\u001b[32m796\u001b[39m shap_values = \u001b[43mexplainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshap_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_sample_flat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnsamples\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnsamples\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    797\u001b[39m shap_values = np.squeeze(shap_values)\n\u001b[32m    798\u001b[39m X_sample = X_sample_flat  \u001b[38;5;66;03m# For plotting\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/shap/explainers/_kernel.py:275\u001b[39m, in \u001b[36mKernelExplainer.shap_values\u001b[39m\u001b[34m(self, X, **kwargs)\u001b[39m\n\u001b[32m    273\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.keep_index:\n\u001b[32m    274\u001b[39m     data = convert_to_instance_with_index(data, column_name, index_value[i : i + \u001b[32m1\u001b[39m], index_name)\n\u001b[32m--> \u001b[39m\u001b[32m275\u001b[39m explanations.append(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mexplain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    276\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m kwargs.get(\u001b[33m\"\u001b[39m\u001b[33mgc_collect\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m    277\u001b[39m     gc.collect()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/shap/explainers/_kernel.py:479\u001b[39m, in \u001b[36mKernelExplainer.explain\u001b[39m\u001b[34m(self, incoming_instance, **kwargs)\u001b[39m\n\u001b[32m    476\u001b[39m     \u001b[38;5;28mself\u001b[39m.kernelWeights[nfixed_samples:] *= weight_left / \u001b[38;5;28mself\u001b[39m.kernelWeights[nfixed_samples:].sum()\n\u001b[32m    478\u001b[39m \u001b[38;5;66;03m# execute the model on the synthetic samples we have created\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m479\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    481\u001b[39m \u001b[38;5;66;03m# solve then expand the feature importance (Shapley value) vector to contain the non-varying features\u001b[39;00m\n\u001b[32m    482\u001b[39m phi = np.zeros((\u001b[38;5;28mself\u001b[39m.data.groups_size, \u001b[38;5;28mself\u001b[39m.D))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/shap/explainers/_kernel.py:624\u001b[39m, in \u001b[36mKernelExplainer.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    622\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.keep_index_ordered:\n\u001b[32m    623\u001b[39m         data = data.sort_index()\n\u001b[32m--> \u001b[39m\u001b[32m624\u001b[39m modelOut = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    625\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(modelOut, (pd.DataFrame, pd.Series)):\n\u001b[32m    626\u001b[39m     modelOut = modelOut.values\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/jovyan/files/utilities.py:793\u001b[39m, in \u001b[36mexplain_lstm_with_shap.<locals>.model_predict\u001b[39m\u001b[34m(X_flat)\u001b[39m\n\u001b[32m    792\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmodel_predict\u001b[39m(X_flat):\n\u001b[32m--> \u001b[39m\u001b[32m793\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_flat\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_flat\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime_steps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py:70\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     67\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m     68\u001b[39m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[32m     69\u001b[39m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m70\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     71\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     72\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/constant_op.py:103\u001b[39m, in \u001b[36mconvert_to_eager_tensor\u001b[39m\u001b[34m(value, ctx, dtype)\u001b[39m\n\u001b[32m    101\u001b[39m     dtype = dtypes.as_dtype(dtype).as_datatype_enum\n\u001b[32m    102\u001b[39m ctx.ensure_initialized()\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[43m.\u001b[49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mInternalError\u001b[39m: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized."
     ]
    }
   ],
   "source": [
    "from utilities import explain_lstm_with_shap\n",
    "\n",
    "print(\"ðŸš€ Running warm-up prediction to initialize GPU...\")\n",
    "_ = model.predict(X_train[:1])\n",
    "\n",
    "\n",
    "explain_lstm_with_shap(\n",
    "    model=model,\n",
    "    X_train=X_train,\n",
    "    X_test=X_test,\n",
    "    feature_cols=feature_cols,  \n",
    "    time_steps=60,\n",
    "    background_size=300,\n",
    "    sample_size=150,\n",
    "    nsamples=100,\n",
    "    plot_filename=\"shap_lstm_v1.png\",\n",
    "    plot_influence ='shap_crypto_influence_louvain'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765a169e-444a-4906-a34d-59cfbc703a8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
