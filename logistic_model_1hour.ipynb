{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25df8174",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from utilities import technical_analysis\n",
    "from utilities import generate_candlestick_patterns\n",
    "import base64\n",
    "from cryptography.hazmat.primitives import serialization\n",
    "from cryptography.hazmat.backends import default_backend\n",
    "from snowflake.sqlalchemy import URL\n",
    "from sqlalchemy import create_engine\n",
    "import os\n",
    "import talib\n",
    "from dotenv import load_dotenv\n",
    "from sqlalchemy import text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c4e180",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "with open(os.getenv(\"PRIVATE_KEY_PATH\"), \"rb\") as key_file:\n",
    "    private_key = serialization.load_pem_private_key(\n",
    "        key_file.read(),\n",
    "        password=None,\n",
    "        backend=default_backend()\n",
    "    )\n",
    "\n",
    "private_key_pkcs8 = base64.b64encode(\n",
    "    private_key.private_bytes(\n",
    "        encoding=serialization.Encoding.DER,\n",
    "        format=serialization.PrivateFormat.PKCS8,\n",
    "        encryption_algorithm=serialization.NoEncryption()\n",
    "    )\n",
    ").decode(\"utf-8\")  # ✅ base64 string, not bytes!\n",
    "\n",
    "engine = create_engine(URL(\n",
    "    account=os.getenv(\"SNOWFLAKE_ACCOUNT\"),\n",
    "    user=os.getenv(\"SNOWFLAKE_USER\"),\n",
    "    private_key=private_key_pkcs8,\n",
    "    warehouse=os.getenv(\"SNOWFLAKE_WAREHOUSE\"),\n",
    "    database=os.getenv(\"SNOWFLAKE_DATABASE\"),\n",
    "    schema=os.getenv(\"SNOWFLAKE_SCHEMA\"),\n",
    "    role=os.getenv(\"SNOWFLAKE_ROLE\")\n",
    "))\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    result = conn.execute(text(\"SELECT CURRENT_USER(), CURRENT_ROLE(), CURRENT_TIMESTAMP();\"))\n",
    "    for row in result:\n",
    "        print(\"✅ Snowflake connected:\", row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced31b35-eeb0-4fdd-a5e3-7d0197758bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from onchain import fetch_all_blockchain_metrics\n",
    "df_blockchain = fetch_all_blockchain_metrics()\n",
    "df_blockchain[['hash_rate','miner_revenue','active_addresses','difficulty']] = df_blockchain[['hash_rate','miner_revenue','active_addresses','difficulty']].ffill()\n",
    "# Fill all numeric NaNs with the column mean\n",
    "df_blockchain = df_blockchain.apply(\n",
    "    lambda col: col.fillna(col.mean()) if pd.api.types.is_numeric_dtype(col) else col\n",
    ")\n",
    "# Repeat daily values over each 15-min slot (divide value into 96 chunks)\n",
    "df_normalized = df_blockchain.resample(\"1h\").ffill()\n",
    "df_normalized[df_blockchain.columns[0]] = df_normalized[df_blockchain.columns[0]] / 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ba3b45-77a1-49ab-9a85-7fed851e587c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_normalized.reset_index(inplace=True)\n",
    "df_normalized['date']=df_normalized['timestamp']\n",
    "df_normalized.drop(columns=(['timestamp']),inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ac1a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT  \n",
    "    btc.date,\n",
    "    btc.open,\n",
    "    btc.close,\n",
    "    btc.high,\n",
    "    btc.low,\n",
    "    btc.volume, \n",
    "    nasd.close AS NASDAQ, \n",
    "    sp500.close AS SP500, \n",
    "    vix.close AS VIX,\n",
    "    dwj.close AS DOWJONES,\n",
    "    (\n",
    "        SELECT min(close ) as close\n",
    "        FROM CRYPTODB.PUBLIC.vw_btc \n",
    "        WHERE date = DATEADD(minute, 15, btc.date)\n",
    "        \n",
    "    ) AS Target\n",
    "FROM CRYPTODB.PUBLIC.vw_btc btc\n",
    "LEFT JOIN CRYPTODB.PUBLIC.vw_nasdaq nasd\n",
    "    ON btc.date = nasd.timestamp\n",
    "LEFT JOIN CRYPTODB.PUBLIC.vw_sp500 sp500\n",
    "    ON btc.date = sp500.timestamp\n",
    "LEFT JOIN CRYPTODB.PUBLIC.vw_vix vix\n",
    "    ON btc.date = vix.timestamp\n",
    "LEFT JOIN CRYPTODB.PUBLIC.vw_dowjones dwj\n",
    "    ON btc.date = dwj.timestamp\n",
    "WHERE btc.date >= '2015-01-01'\n",
    "ORDER BY btc.date ASC\n",
    "\"\"\"\n",
    "\n",
    "data = pd.read_sql(query,con=engine)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60198d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.DataFrame()\n",
    "df = data.copy()\n",
    "df[['nasdaq', 'sp500', 'vix', 'dowjones']] = df[['nasdaq', 'sp500', 'vix', 'dowjones']].ffill()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6b0080-8d39-41d1-a69b-893051e7904b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.resample('1H', on='date').agg({\n",
    "    'open': 'first',\n",
    "    'high': 'max',\n",
    "    'low': 'min',\n",
    "    'close': 'last',\n",
    "    'volume': 'sum',\n",
    "    'nasdaq': 'last',\n",
    "    'sp500': 'last',\n",
    "    'vix': 'last',\n",
    "    'dowjones': 'last',\n",
    "    # Other numeric on-chain features: 'mean' or 'last'\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e077396b-85dc-40f8-9a9b-ab71723c55fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = [col.capitalize() for col in df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f496a7b-9b73-4cab-bd43-76a5d3849ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df, df_normalized, on='date', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3d8bcc-f082-4914-a0ac-3d417b360453",
   "metadata": {},
   "outputs": [],
   "source": [
    "from clusteranalysis import perform_kmeans_with_elbow_silhouette\n",
    "from utilities import technical_analysis, generate_candlestick_patterns\n",
    "\n",
    "def prepare_pipeline(df_raw):\n",
    "    # Step 1: Add technical indicators\n",
    "    df_ta = technical_analysis(df_raw.copy())\n",
    "\n",
    "    # Step 2: Add candlestick pattern features\n",
    "    df_patterns = generate_candlestick_patterns(df_ta)\n",
    "\n",
    "    # Step 3: Perform clustering\n",
    "    df_clustered = perform_kmeans_with_elbow_silhouette(df_patterns,plot=False)\n",
    "\n",
    "    return df_clustered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ec4f92-a949-4969-ad20-465c8fcbc385",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbec47fd-b787-4548-afe9-e4155039fa10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_return(r, threshold=0.003):\n",
    "    if r > threshold:\n",
    "        return 1   # up\n",
    "    elif r < -threshold:\n",
    "        return -1  # down\n",
    "    else:\n",
    "        return 0   # neutral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3524e392-525c-4b4e-8153-d9dfc2cbea21",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = df.copy()\n",
    "df_output = prepare_pipeline(df_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4570c683",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from clusteranalysis import perform_kmeans_with_elbow_silhouette\n",
    "\n",
    "\n",
    "df_output['target_return'] = df_output['Close'].shift(-1) / df['Close'] - 1\n",
    "df_output['target_class'] = df_output['target_return'].apply(classify_return).astype(int)\n",
    "\n",
    "df_output['return_t-1'] = df['target_return'].shift(1)\n",
    "df_output['rolling_vol'] = df['target_return'].rolling(10).std()\n",
    "\n",
    "import numpy as np\n",
    "df_output['log_return'] = np.log(df_output['Close'] / df['Close'].shift(1))  # past return (t-1)\n",
    "df_output['log_return_t-1'] = df_output['log_return'].shift(1)\n",
    "df_output['log_return_sum_3'] = df_output['log_return'].rolling(3).sum()\n",
    "\n",
    "df_output['slope'] = df_output['Close'].diff(3)\n",
    "\n",
    "# Your base features\n",
    "numerical_features = ['Nasdaq', 'Volume','hash_rate','miner_revenue','active_addresses','difficulty','log_return','log_return_t-1','log_return_sum_3','slope','MACD',\n",
    "                     'MACD_Signal','MFI','RSI','Bollinger_Upper','Bollinger_Lower','Stochastic']\n",
    "categorical_features = [\n",
    "   'pattern_label'\n",
    "]\n",
    "\n",
    "# Combine them\n",
    "all_features = numerical_features + categorical_features\n",
    "\n",
    "# Prepare the dataframe\n",
    "df_model = df_output.dropna(subset=all_features + ['target_class'])\n",
    "\n",
    "X = df_model[all_features]\n",
    "y = df_model['target_class']\n",
    "\n",
    "# One-hot encode categorical columns\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_features),\n",
    "        ('cat', OneHotEncoder(drop='first', handle_unknown='ignore'), categorical_features)\n",
    "    ]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12f2a67-d3c0-46ca-820d-e6c053a5a087",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075fd0c8-a8cf-4e64-b4a8-1f3c9f7c62ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# Now you can plug this into your model:\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=200, max_depth=10, class_weight='balanced', random_state=42)\n",
    "\n",
    "#RandomForestClassifier(n_estimators=200, max_depth=10, random_state=42)\n",
    "\n",
    "# Split BEFORE transforming\n",
    "X_train_raw, X_test_raw, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, shuffle=False  # no shuffle for time series\n",
    ")\n",
    "\n",
    "# Fit-transform on training, transform on test\n",
    "X_train = preprocessor.fit_transform(X_train_raw)\n",
    "X_test = preprocessor.transform(X_test_raw)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50121587-4292-446d-b75e-a5296524eced",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📊 Model Evaluation Metrics Explained:\n",
    "#\n",
    "# - Accuracy: Overall, how often the model is correct.\n",
    "#             (Good for balanced datasets, less useful when classes are imbalanced)\n",
    "#\n",
    "# - Precision: Of all predicted \"Up\" signals (class 1), how many were actually correct?\n",
    "#              High precision = fewer false positive trades (i.e., false buy signals).\n",
    "#\n",
    "# - Recall: Of all actual \"Up\" moments in the market, how many did we successfully detect?\n",
    "#           High recall = fewer missed opportunities (captures more real upward moves).\n",
    "#\n",
    "# - F1 Score: The harmonic mean of Precision and Recall.\n",
    "#             A balanced measure useful when we care about both false positives and false negatives.\n",
    "#\n",
    "# In trading contexts:\n",
    "# 👉 Precision favors capital preservation (less false buys).\n",
    "# 👉 Recall favors opportunity capture (more trades, but possibly riskier).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66171170-51c8-49ac-8ad7-cf8f53fc04eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Replace these with your actual predictions and labels\n",
    "labels = [-1, 0, 1]\n",
    "label_names = ['Down (-1)', 'Neutral (0)', 'Up (1)']\n",
    "cm = confusion_matrix(y_test, y_pred, labels=labels)\n",
    "df_cm = pd.DataFrame(cm, index=label_names, columns=label_names)\n",
    "\n",
    "# Create a heatmap\n",
    "fig = go.Figure(data=go.Heatmap(\n",
    "    z=df_cm.values,\n",
    "    x=label_names,\n",
    "    y=label_names,\n",
    "    colorscale='Blues',\n",
    "    colorbar=dict(title='Count')\n",
    "))\n",
    "\n",
    "# Add annotations\n",
    "for i in range(df_cm.shape[0]):\n",
    "    for j in range(df_cm.shape[1]):\n",
    "        fig.add_annotation(\n",
    "            x=label_names[j],\n",
    "            y=label_names[i],\n",
    "            text=str(df_cm.iloc[i, j]),\n",
    "            showarrow=False,\n",
    "            font=dict(color=\"black\")\n",
    "        )\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Confusion Matrix (Multiclass)',\n",
    "    xaxis_title='Predicted Label',\n",
    "    yaxis_title='True Label',\n",
    "    width=700,\n",
    "    height=500\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482142f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = model.feature_importances_\n",
    "feature_names = preprocessor.get_feature_names_out()\n",
    "sorted_idx = importances.argsort()[::-1]\n",
    "\n",
    "print(\"🔍 Top 15 Most Important Features:\")\n",
    "for idx in sorted_idx[:15]:\n",
    "    print(f\"{feature_names[idx]}: {importances[idx]:.4f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0ff1db-c27a-4cc3-8e0e-eeb489e7e983",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
