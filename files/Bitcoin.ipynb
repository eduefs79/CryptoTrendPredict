{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f17af33-7359-4d55-8069-6b89dbfbcd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639b855e-efc2-4661-beab-9159d6f06698",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install simplejson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9d6474-8cda-4ce1-8de6-02682b71ded3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5555599-b2d0-41ef-b45f-3dad4811b5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install yfinance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f96dc3-8420-4830-acb6-fc83d4ed5f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install sqlalchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63166c48-52e5-43be-9864-1acdabcd7801",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install pymysql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5025d7-5277-4873-89d0-b13d572316d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install pandas_datareader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47e4a3e-d4dd-421c-bb9d-458fcef5d3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install ta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8a597c-3676-49ba-a1c4-25dd188ae5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def install_dependencies(packages):\n",
    "    \"\"\"\n",
    "    Installs only the missing packages or reinstalls them if they already exist.\n",
    "\n",
    "    Args:\n",
    "        packages (dict): A dictionary where the key is the package name \n",
    "                         and the value is the version (optional).\n",
    "    \"\"\"\n",
    "    for package, version in packages.items():\n",
    "        try:\n",
    "            # Check if the package is already installed\n",
    "            importlib.import_module(package)\n",
    "            print(f\"{package} is already installed. Uninstalling and reinstalling...\")\n",
    "            # Uninstall the package if it's already installed\n",
    "            #subprocess.check_call([sys.executable, \"-m\", \"pip\", \"uninstall\", f\"{package}\", \"-y\"])\n",
    "        except ImportError:\n",
    "            print(f\"{package} is not installed. Installing now...\")\n",
    "\n",
    "        # Install the package (after uninstalling if it existed)\n",
    "        if version:\n",
    "            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", f\"{package}=={version}\", \"--upgrade\", \"--no-cache-dir\"])\n",
    "        else:\n",
    "            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package, \"--upgrade\", \"--no-cache-dir\"])\n",
    "\n",
    "# Define your dependencies (key: package name, value: version or None for latest)\n",
    "dependencies = {\n",
    "    \"requests\": None,\n",
    "    #\"numpy\": \"1.24.4\",\n",
    "    \"yfinance\": None,\n",
    "    \"simplejson\": None,\n",
    "    \"matplotlib\": None,\n",
    "    \"sqlalchemy\": None,\n",
    "    \"pymysql\": None,\n",
    "    \"pandas_datareader\": None,\n",
    "    \"ta\": None   \n",
    "}\n",
    "\n",
    "# Install the required dependencies\n",
    "install_dependencies(dependencies)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1db9ea-992b-4b03-af1d-c8a6922cf06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6a443f-03b8-4bad-9637-1e0c7a7e4aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datetime import datetime,timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621be772-03b1-4854-b765-cdceafe0b9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e88474-5bde-41a1-bcc3-3368fefdaf7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "path = os.path.join('/home','jovyan','files', 'datasets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3621ade1-c87b-4e89-b0dc-5425cf3a8d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def convert_to_date(date_string, date_format=\"%Y-%m-%d\"):\n",
    "    \"\"\"\n",
    "    Converts a date string to a datetime object.\n",
    "    \n",
    "    Args:\n",
    "        date_string (str): The date as a string.\n",
    "        date_format (str): The format of the date string (default is '%Y-%m-%d').\n",
    "    \n",
    "    Returns:\n",
    "        datetime: A datetime object representing the date, or None if conversion fails.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return datetime.strptime(date_string, date_format)\n",
    "    except ValueError:\n",
    "        print(f\"Error: '{date_string}' does not match the format '{date_format}'\")\n",
    "        return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748fc897-695e-4ef6-8f80-999d880c337d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "\n",
    "\n",
    "\n",
    "def fetch_daily_data(symbol, start_date, end_date):\n",
    "    # Download historical data from Yahoo Finance\n",
    "    ticker = yf.Ticker(symbol)  # Symbol is like 'BTC-USD', 'ETH-USD', etc.\n",
    "    #path =f'/../datasets'\n",
    "   \n",
    "    # Fetch data for the specified date range\n",
    "    data = ticker.history(start=start_date, end=end_date, interval=\"1d\")\n",
    "  \n",
    "    if data.empty:\n",
    "        print(f\"No data available for {symbol} between {start_date} and {end_date}\")\n",
    "    else:\n",
    "        # File name based on symbol and start date\n",
    "        filename = f'Yahoo_Finance_{symbol}_{start_date.strftime(\"%Y_%m_%d\")}.csv'\n",
    "\n",
    "           \n",
    "         # Convert 'Date' column to datetime if not already\n",
    "        #data['NewDate'] = convert_to_date (data['Date'])\n",
    "\n",
    "        # Process data\n",
    "        data['vol_fiat'] = data['Volume'] * data['Close']  # Calculate fiat volume\n",
    "        data['Provider'] = \"Yahoo Finance\"\n",
    "        data['Asset'] = symbol\n",
    "        \n",
    "        # Save to CSV\n",
    "        file_path = os.path.join(path, filename)\n",
    "        data.to_csv(file_path, index=True)  # 'index=True' to include the date column\n",
    "        print(f\"Data saved to {filename}\")\n",
    "\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775f781e-7854-4fb4-80ce-cffadac0b5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    pair = \"BTC-USD\"\n",
    "    start = datetime.strptime(\"2015-01-01\",\"%Y-%m-%d\")\n",
    "    today = pd.to_datetime('today').normalize()\n",
    "    while(start <= today):\n",
    "        end = start + timedelta(days=180)\n",
    "        fetch_daily_data(symbol=pair,start_date=start,end_date=end)\n",
    "        start = end + timedelta(days=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38d0a77-b166-4935-87e8-209f9a811f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "combined_df = \"\"\n",
    "\n",
    "csv_files = glob.glob(f\"{path}/Yahoo_Finance_BTC-USD*.csv\")\n",
    "\n",
    "dataframes = []\n",
    "\n",
    "for file in csv_files:\n",
    "    df = pd.read_csv(file)\n",
    "    dataframes.append(df)\n",
    "\n",
    "combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "combined_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9f7928-ba11-4178-9f99-d8629f09adc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "engine = create_engine('mysql+pymysql://<user>::<pwd>@172.28.0.2:3306/bitcoin_db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ee379b-10c4-419b-952b-cd3cdf43077d",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.to_sql('crypto', con=engine, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86b1279-d749-4444-88e9-76bc5701245f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://alternative.me/crypto/fear-and-greed-index/\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "url = 'https://api.alternative.me/fng/?limit=0'\n",
    "\n",
    "response = requests.get(url)\n",
    "response.raise_for_status()  \n",
    "data = response.json()['data']\n",
    "df = pd.DataFrame(data)\n",
    "# Convert 'timestamp' to datetime and set timezone to UTC\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'], unit='s', utc=True)\n",
    "df.to_sql('FearGreedIndex', con=engine, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd390824-2efe-4168-8b8c-5fbc8e36cc85",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT `Date`, `Open`, High, Low, `Close`, Volume, cast(fgi.value AS UNSIGNED) as FGI\n",
    "FROM bitcoin_db.crypto btc\n",
    "LEFT JOIN bitcoin_db.FearGreedIndex fgi\n",
    "ON btc.`Date` = fgi.`timestamp`\n",
    "\"\"\"\n",
    "\n",
    "data = pd.read_sql(query,con=engine).sort_values(by='Date')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5536e7d-b5be-4de2-8008-c227abe8b3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the average of the FGI column, excluding NaN values\n",
    "fg_average = data['FGI'].mean()\n",
    "\n",
    "# Fill NaN values in the FGI column with the calculated average\n",
    "data['FGI'].fillna(fg_average, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea93d942-1fc5-462d-b43b-19bd61bdaf38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6560449d-4060-4430-b7f4-6a1c2cf84a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.investopedia.com/terms/m/macd.asp\n",
    "#macd_object = ta.trend.MACD(data['close'])\n",
    "macd_object = ta.trend.MACD(data['Close'], window_slow = 26, window_fast = 12, window_sign = 9, fillna= True)\n",
    "data['MACD'] = macd_object.macd()\n",
    "data['MACD_Signal'] = macd_object.macd_signal()\n",
    "data['MACD_Diff'] = macd_object.macd_diff()\n",
    "#data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f70b4f-e403-451d-9e67-cf36ff45fdba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.investopedia.com/terms/m/mfi.asp\n",
    "mfi_indicator = ta.volume.MFIIndicator(high=data['High'], low=data['Low'], close=data['Close'], volume=data['Volume'], window=14)\n",
    "data['mfi'] = mfi_indicator.money_flow_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aad93b0-9ffd-4047-a6e6-1faf6db69d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RSI\n",
    "rsi = ta.momentum.rsi(data['Close'], window=14, fillna=True)\n",
    "data['RSI'] = rsi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d6f094-01d4-4ac9-8553-50c51036afa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EMA\n",
    "ema_short = ta.trend.EMAIndicator(data['Close'], window=12, fillna=True)\n",
    "ema_long = ta.trend.EMAIndicator(data['Close'], window=26, fillna=True)\n",
    "data['EMA_Short'] = ema_short.ema_indicator()\n",
    "data['EMA_Long'] = ema_long.ema_indicator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae344ddb-1c91-4179-895b-21d91f8ac9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bollinger Bands\n",
    "bollinger = ta.volatility.BollingerBands(data['Close'], window=20, window_dev=2, fillna=True)\n",
    "data['Bollinger_Upper'] = bollinger.bollinger_hband()\n",
    "data['Bollinger_Lower'] = bollinger.bollinger_lband()\n",
    "data['Bollinger_Middle'] = bollinger.bollinger_mavg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b91148-d15e-4e00-8d89-0c1545cfb970",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stochastic Oscillator\n",
    "stoch = ta.momentum.StochasticOscillator(data['High'], data['Low'], data['Close'], window=14, smooth_window=3, fillna=True)\n",
    "data['Stochastic'] = stoch.stoch()\n",
    "data['Stochastic_Signal'] = stoch.stoch_signal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1daf30-3b21-4799-86da-af35952b4413",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ATR\n",
    "atr = ta.volatility.AverageTrueRange(data['High'], data['Low'], data['Close'], window=14, fillna=True)\n",
    "data['ATR'] = atr.average_true_range()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403f1e49-9637-4616-8956-721b9369596b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parabolic SAR\n",
    "sar = ta.trend.PSARIndicator(data['High'], data['Low'], data['Close'], fillna=True)\n",
    "data['SAR'] = sar.psar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38249fea-31b5-4d52-9320-d539534346de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Prepare the data (assuming 'data' is already pre-processed with features)\n",
    "data['Date'] = pd.to_datetime(data['Date'], utc=True)\n",
    "data['Target'] = data['Close'].shift(-1)\n",
    "data = data.dropna(subset=['Target'])\n",
    "\n",
    "# Select features (excluding 'Date')\n",
    "features = [\n",
    "     'Bollinger_Upper', 'Bollinger_Lower', 'Bollinger_Middle','FGI', 'Close'\n",
    "]\n",
    "\n",
    "X = data[features]\n",
    "y = data['Target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe107683-4e1e-4f70-9ae9-378a272549c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff12fe6-6ff6-4928-b193-f1f64ef830ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler on the training data and transform both train and test data\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train the model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b652149-ee7c-4e5b-b07f-66c8d9c57100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Absolute Error: {mae}\")\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "print(f\"R-squared: {r2}\")\n",
    "\n",
    "# Make predictions for the next closing price\n",
    "# Use the last row from X_test (or any new data)\n",
    "latest_data = X_test.iloc[-1:]  # Keep it as a DataFrame (not numpy array)\n",
    "\n",
    "# Apply the same scaling to the latest data\n",
    "latest_data_scaled = scaler.transform(latest_data)  # The feature names are kept\n",
    "\n",
    "# Make prediction for the next closing price\n",
    "next_close_pred = model.predict(latest_data_scaled)\n",
    "print(f\"Predicted next closing price: {next_close_pred[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5656a3-5aad-4898-be4c-feaba7e7bbf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the coefficients and the intercept\n",
    "coefficients = model.coef_\n",
    "intercept = model.intercept_\n",
    "\n",
    "# Create a dictionary mapping feature names to their corresponding coefficients\n",
    "feature_names = X.columns\n",
    "equation = f\"Predicted next closing price = {intercept:.2f}\"\n",
    "\n",
    "# Add each feature and its coefficient to the equation\n",
    "for feature, coef in zip(feature_names, coefficients):\n",
    "    equation += f\" + ({coef:.2f}) * {feature}\"\n",
    "\n",
    "# Display the equation\n",
    "print(\"Final equation for predicting the next closing price:\")\n",
    "print(equation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a696a450-b367-42d0-bd29-aee107e6ee0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a DataFrame to store the actual vs predicted values\n",
    "results = pd.DataFrame({\n",
    "    'Date': X_test.index,\n",
    "    'Actual': y_test,\n",
    "    'Predicted': y_pred\n",
    "})\n",
    "\n",
    "# Plotting the actual vs predicted closing prices\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(results['Date'], results['Actual'], label='Actual Closing Price', color='blue', alpha=0.7)\n",
    "plt.plot(results['Date'], results['Predicted'], label='Predicted Closing Price', color='red', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Add titles and labels\n",
    "plt.title('Actual vs Predicted Closing Prices', fontsize=16)\n",
    "plt.xlabel('Date', fontsize=14)\n",
    "plt.ylabel('Price (USD)', fontsize=14)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Display the plot\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()  # Adjust layout to fit labels\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc6c3b7-10e8-4600-a5dd-3d995cb794d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "# Store original column names\n",
    "original_columns = X_train.columns\n",
    "\n",
    "# Standardize the features (X_train_scaled) for fitting the model\n",
    "X_with_intercept = sm.add_constant(X_train_scaled)  # Add intercept term to the features\n",
    "y_train_array = y_train.values  # Convert to numpy array for Statsmodels compatibility\n",
    "\n",
    "# Fit the model using Statsmodels\n",
    "model_sm = sm.OLS(y_train_array, X_with_intercept)  # Ordinary Least Squares Regression\n",
    "results = model_sm.fit()  # Fit the model\n",
    "\n",
    "# Display the summary, which includes the p-values for each feature\n",
    "summary = results.summary()\n",
    "\n",
    "# Map p-values to the original feature names\n",
    "p_values = results.pvalues[1:]  # Exclude the intercept (constant)\n",
    "features_with_p_values = dict(zip(original_columns, p_values))\n",
    "\n",
    "# Print the p-values for each feature and check significance\n",
    "print(\"Feature p-values (human-readable labels):\")\n",
    "for feature, p_value in features_with_p_values.items():\n",
    "    significance = \"Significant\" if p_value < 0.05 else \"Not Significant\"\n",
    "    print(f\"{feature}: {p_value:.4f} ({significance})\")\n",
    "\n",
    "# Optionally, print the full summary\n",
    "print(\"\\nFull summary with p-values:\")\n",
    "print(summary)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e74f729-d5e7-4fbe-b386-39f32b7458ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
