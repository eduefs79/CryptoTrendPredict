{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19cdf4d-e3e7-496f-8509-948431d149b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import utilities  # your module\n",
    "\n",
    "importlib.reload(utilities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1db9ea-992b-4b03-af1d-c8a6922cf06b",
   "metadata": {
    "id": "7f1db9ea-992b-4b03-af1d-c8a6922cf06b"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import json\n",
    "from datetime import datetime,timedelta\n",
    "import requests\n",
    "import ta\n",
    "import base64\n",
    "from cryptography.hazmat.primitives import serialization\n",
    "from cryptography.hazmat.backends import default_backend\n",
    "from snowflake.sqlalchemy import URL\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy import text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f10b363",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0f10b363",
    "outputId": "d50ecd1d-fccd-40f3-c0c1-34dd0ef4cafa"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438709e3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "438709e3",
    "outputId": "e154e80c-cc4c-40b1-b91e-7271d0bc6978"
   },
   "outputs": [],
   "source": [
    "with open(os.getenv(\"PRIVATE_KEY_PATH\"), \"rb\") as key_file:\n",
    "    private_key = serialization.load_pem_private_key(\n",
    "        key_file.read(),\n",
    "        password=None,\n",
    "        backend=default_backend()\n",
    "    )\n",
    "\n",
    "private_key_pkcs8 = base64.b64encode(\n",
    "    private_key.private_bytes(\n",
    "        encoding=serialization.Encoding.DER,\n",
    "        format=serialization.PrivateFormat.PKCS8,\n",
    "        encryption_algorithm=serialization.NoEncryption()\n",
    "    )\n",
    ").decode(\"utf-8\")  # ✅ base64 string, not bytes!\n",
    "\n",
    "engine = create_engine(URL(\n",
    "    account=os.getenv(\"SNOWFLAKE_ACCOUNT\"),\n",
    "    user=os.getenv(\"SNOWFLAKE_USER\"),\n",
    "    private_key=private_key_pkcs8,\n",
    "    warehouse=os.getenv(\"SNOWFLAKE_WAREHOUSE\"),\n",
    "    database=os.getenv(\"SNOWFLAKE_DATABASE\"),\n",
    "    schema=os.getenv(\"SNOWFLAKE_SCHEMA\"),\n",
    "    role=os.getenv(\"SNOWFLAKE_ROLE\")\n",
    "))\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    result = conn.execute(text(\"SELECT CURRENT_USER(), CURRENT_ROLE(), CURRENT_TIMESTAMP();\"))\n",
    "    for row in result:\n",
    "        print(\"✅ Snowflake connected:\", row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8003286e-cc1a-44b3-8bfb-c5da0ea162a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "execution_time = datetime.now().strftime(\"%Y%m%d%H%M%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e2dc6f-6a49-419e-b63f-fceef275cef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "top100 = pd.read_csv('Assets_Categorized.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277cc975-af83-464d-97ef-7bc4b23143e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "top100['staging'] = '@cryptodatasource'\n",
    "top100.drop(columns=['realticker'],inplace=True)\n",
    "#if top100['market'] == 'Crypto':\n",
    "#    top100['ticker'] = top100['ticker']+'-USD'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a4a481-b9a2-45d0-9c76-1d264282bd41",
   "metadata": {},
   "outputs": [],
   "source": [
    "top100.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3519776f-0da5-4fe2-8b8c-f2bb0a48edf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities import download_yahoo_to_stage\n",
    "\n",
    "now = datetime(datetime.now().year,datetime.now().month,datetime.now().day)\n",
    "start_date = datetime(2019, 1, 1)\n",
    "\n",
    "for index, row in top100.iterrows():\n",
    "    # Safe SQL string formatting using :params\n",
    "    query = text(\"SELECT coalesce(dateadd(day,1,MAX(date)),'2019-01-01') as date FROM PUBLIC.VW_CRYPTO WHERE ticker = :ticker \")\n",
    "     #query = text(\"SELECT dateadd(day,1,cast(date_trunc('day',MAX(date)) as date)) as date FROM PUBLIC.VW_CRYPTO WHERE ticker = :ticker \")\n",
    "    df_date = pd.read_sql(query, con=engine, params={\"ticker\": row['ticker']})\n",
    "    start_date = pd.to_datetime(df_date['date'].iloc[0])\n",
    "     \n",
    "    if start_date > now:\n",
    "        print(f\"✅ {row['ticker']}: Up to date — skipping download.\")\n",
    "    else:\n",
    "        # Download only what’s missing\n",
    "        download_yahoo_to_stage(\n",
    "            ticker=row['ticker'],\n",
    "            private_key=private_key,\n",
    "            stage_area=row['staging'],\n",
    "            interval=\"1d\",\n",
    "            start=start_date,\n",
    "            time=\"12:00 AM\",\n",
    "            execution_time=execution_time\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc80c32c-e6ab-4019-9dda-0c968b5462ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import text\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Step 1: Load and merge\n",
    "query = text(\"\"\"\n",
    "    SELECT DISTINCT date, open,high,low,close, volume, ticker\n",
    "    FROM PUBLIC.VW_CRYPTO\n",
    "    WHERE date >= '2020-01-01'\n",
    "    and ticker in ( select distinct ticker from vw_crypto where date <='2020-01-01')\n",
    "    ORDER BY ticker, date\n",
    "\"\"\")\n",
    "data = pd.read_sql(query, con=engine)\n",
    "data.drop_duplicates(['date', 'ticker'], keep='last', inplace=True)\n",
    "\n",
    "data = pd.merge(data, top100, on='ticker', how='left')\n",
    "data = data[data['category'] != 'Stablecoin']\n",
    "\n",
    "print(\"✅ Loaded data for tickers:\", data['ticker'].nunique())\n",
    "\n",
    "\n",
    "ohlcv_cols = ['open', 'high', 'low', 'close', 'volume']\n",
    "data = data.sort_values(by=['ticker', 'date'])\n",
    "\n",
    "for col in ohlcv_cols:\n",
    "    # Fill forward, then backward, then with mean (per ticker)\n",
    "    data[col] = (\n",
    "        data.groupby('ticker')[col]\n",
    "        .apply(lambda grp: grp.ffill().bfill().fillna(grp.mean()))\n",
    "        .reset_index(level=0, drop=True)\n",
    "    )\n",
    "\n",
    "nan_summary = data[ohlcv_cols].isna().sum()\n",
    "print(\"🧹 Still NaNs in `data` (should be 0):\")\n",
    "print(nan_summary[nan_summary > 0])\n",
    "\n",
    "\n",
    "# Step 2: Pivot close prices\n",
    "price_df = data.pivot(index='date', columns='ticker', values='close')\n",
    "\n",
    "# b. Fill remaining NaNs with the average of the column\n",
    "price_df = price_df.apply(lambda col: col.fillna(col.mean()), axis=0)\n",
    "\n",
    "# Step 4: Optional check\n",
    "nan_summary = price_df.isna().sum()\n",
    "print(\"🧹 Still NaN per ticker (should be 0):\")\n",
    "print(nan_summary[nan_summary > 0])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdec8a3a-e75b-4d9f-afd5-6c21d585c43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "topN = 70\n",
    "required_tickers = ['BTC-USD', 'ETH-USD','GC=F','SI=F','^GSPC','^NDX','BTC-RUB','BTC-GBP','BTC-CNY','BTC-INR','^VIX']\n",
    "\n",
    "top_tickers = price_df.notna().sum().sort_values(ascending=False).head(topN).index.tolist()\n",
    "\n",
    "for ticker in required_tickers:\n",
    "    if ticker not in top_tickers and ticker in price_df.columns:\n",
    "        top_tickers.append(ticker)\n",
    "\n",
    "# Optional: Deduplicate while preserving order\n",
    "top_tickers = list(dict.fromkeys(top_tickers))\n",
    "\n",
    "filtered_price_df = price_df[top_tickers]\n",
    "\n",
    "# Step 3: Clean prices (remove 0s), then compute log returns\n",
    "cleaned_prices = filtered_price_df.replace(0, np.nan)\n",
    "returns = np.log(cleaned_prices / cleaned_prices.shift(1)).dropna()\n",
    "\n",
    "# Step 4: Correlation + Distance matrix\n",
    "corr_matrix = returns.corr()\n",
    "distance_matrix = np.sqrt(2 * (1 - corr_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55f0846-3baa-4be6-a76d-86fdcd6df769",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(top_tickers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14cd832-6ab0-4bba-b5c9-202e0ea174c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "\n",
    "# Clean the distance matrix\n",
    "clean_distance = distance_matrix.dropna(axis=0, how='any').dropna(axis=1, how='any')\n",
    "\n",
    "# Step 1: Create an undirected graph\n",
    "G = nx.Graph()\n",
    "\n",
    "# Add nodes (tickers)\n",
    "for ticker in clean_distance.columns:\n",
    "    G.add_node(ticker)\n",
    "\n",
    "# Add edges with weights (distances)\n",
    "for i in range(len(clean_distance.columns)):\n",
    "    for j in range(i + 1, len(clean_distance.columns)):\n",
    "        t1 = clean_distance.columns[i]\n",
    "        t2 = clean_distance.columns[j]\n",
    "        dist = clean_distance.iloc[i, j]\n",
    "        if pd.notnull(dist):\n",
    "            G.add_edge(t1, t2, weight=dist)\n",
    "\n",
    "# Step 2: Create Minimum Spanning Tree (MST)\n",
    "mst = nx.minimum_spanning_tree(G)\n",
    "\n",
    "# Step 3: Calculate centrality metrics (using eigenvector_centrality_numpy)\n",
    "centrality = {\n",
    "    'degree': nx.degree_centrality(mst),\n",
    "    'betweenness': nx.betweenness_centrality(mst),\n",
    "    'closeness': nx.closeness_centrality(mst),\n",
    "    'eigenvector': nx.eigenvector_centrality_numpy(mst)  # <-- numpy method (robust)\n",
    "}\n",
    "\n",
    "# Combine into a DataFrame\n",
    "centrality_df = pd.DataFrame(centrality)\n",
    "\n",
    "# Preview top nodes by eigenvector centrality\n",
    "print(centrality_df.sort_values(by='eigenvector', ascending=False).head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eaf5942-aa6d-4b12-9838-d75b4356dc56",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Total nodes in MST: {len(mst.nodes())}\")\n",
    "print(f\"Total edges in MST: {len(mst.edges())}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a8eb72-8024-4aea-9d42-27b2d74ed73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "centrality_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f84662f-f335-41d4-a1b3-183cce6f11a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "\n",
    "# Use spring layout for positioning\n",
    "pos = nx.spring_layout(mst, seed=42, k=0.3)\n",
    "\n",
    "# Centrality scores\n",
    "eigen = centrality_df['eigenvector']\n",
    "closeness = centrality_df['closeness']\n",
    "\n",
    "# Normalize node sizes and colors\n",
    "node_sizes = 1000 * (eigen - eigen.min()) / (eigen.max() - eigen.min()) + 300\n",
    "norm_closeness = (closeness - closeness.min()) / (closeness.max() - closeness.min())\n",
    "\n",
    "# Edge weights and colors based on inverse distance\n",
    "edge_weights = [1 / mst[u][v]['weight'] for u, v in mst.edges()]\n",
    "edge_colors = edge_weights\n",
    "\n",
    "# Set up plot\n",
    "fig, ax = plt.subplots(figsize=(14, 10))\n",
    "\n",
    "# Draw nodes\n",
    "nodes = nx.draw_networkx_nodes(\n",
    "    mst, pos,\n",
    "    node_size=node_sizes,\n",
    "    node_color=norm_closeness,\n",
    "    cmap=plt.cm.turbo,\n",
    "    ax=ax\n",
    ")\n",
    "\n",
    "# Draw edges with color mapping\n",
    "edges = nx.draw_networkx_edges(\n",
    "    mst, pos,\n",
    "    width=edge_weights,\n",
    "    edge_color=edge_colors,\n",
    "    edge_cmap=plt.cm.plasma,\n",
    "    edge_vmin=min(edge_colors),\n",
    "    edge_vmax=max(edge_colors),\n",
    "    alpha=0.6,\n",
    "    ax=ax\n",
    ")\n",
    "\n",
    "# Draw labels\n",
    "nx.draw_networkx_labels(\n",
    "    mst, pos,\n",
    "    font_size=10,\n",
    "    font_family='serif',\n",
    "    ax=ax\n",
    ")\n",
    "\n",
    "# Highlight top eigenvector nodes\n",
    "#top_n = eigen.sort_values(ascending=False).head(5).index\n",
    "#for node in top_n:\n",
    "#    x, y = pos[node]\n",
    "#    ax.text(x, y + 0.05, f\"[Top] {node}\", fontsize=9, ha='center', color='gold')\n",
    "    #ax.text(x, y + 0.05, f\"⭐ {node}\", fontsize=9, ha='center', color='gold')\n",
    "\n",
    "# Add colorbar for node color\n",
    "sm = plt.cm.ScalarMappable(cmap=plt.cm.turbo, norm=plt.Normalize(vmin=closeness.min(), vmax=closeness.max()))\n",
    "sm.set_array([])\n",
    "cbar = plt.colorbar(sm, ax=ax)\n",
    "cbar.set_label(\"Closeness Centrality\")\n",
    "\n",
    "# Final formatting\n",
    "ax.set_title(\"Crypto Network (MST)\\nSize = Eigenvector | Color = Closeness | Edge = Correlation Strength\", fontsize=14)\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f311234f-c0f0-4888-a950-906025551622",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_price_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba5b81d-5309-4c01-b304-4921400e8a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities import cluster_from_correlation\n",
    "\n",
    "data.isna().sum()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81011ad8-0f22-49d4-9c34-deb433efd112",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_corr = cluster_from_correlation(data, k=4)\n",
    "cluster_corr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166c285c-31b3-48d2-b9fe-bd77db8ea8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.countplot(data=cluster_corr, x='cluster', palette='tab10')\n",
    "plt.title('Number of Coins per Cluster')\n",
    "plt.xlabel('Cluster')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0dc4791-cd19-4a0f-a9bd-69a809bfdf5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "btc_cluster = cluster_corr[cluster_corr['ticker']=='BTC-USD']['cluster'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a28fb4-f6b9-4936-a3f9-07be8cb4067d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_corr[cluster_corr['cluster']==btc_cluster]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1504202-571e-4dff-a455-3e75cfd89888",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities import louvain_from_returns\n",
    "#print(data['ticker'].unique())\n",
    "cluster_louvain,G,clustered_returns = louvain_from_returns(data, min_corr=0.5, plot=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6213ff1-8d64-4936-aab9-f5d9efab152e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities import technical_analysis\n",
    "\n",
    "btc_df = data[data['ticker'] == 'BTC-USD'].copy()\n",
    "btc_df = technical_analysis(btc_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de29b97-8bbc-4a0e-bca2-385adce9f962",
   "metadata": {},
   "outputs": [],
   "source": [
    "btc_cluster = cluster_louvain[cluster_louvain['ticker'] == 'BTC-USD']['cluster'].values[0]\n",
    "peer_tickers = cluster_louvain[(cluster_louvain['cluster'] == btc_cluster) & \n",
    "                                (cluster_louvain['ticker'] != 'BTC-USD')]['ticker'].tolist()\n",
    "\n",
    "# Filter and pivot\n",
    "peer_df = data[data['ticker'].isin(peer_tickers)]\n",
    "peer_prices = peer_df.pivot(index='date', columns='ticker', values='close').sort_index()\n",
    "\n",
    "\n",
    "# Get all unique clusters\n",
    "unique_clusters = cluster_louvain['cluster'].unique()\n",
    "\n",
    "# Plot each cluster as a subgraph\n",
    "for cluster_id in sorted(unique_clusters):\n",
    "    tickers_in_cluster = cluster_louvain[cluster_louvain['cluster'] == cluster_id]['ticker'].tolist()\n",
    "    subgraph = G.subgraph(tickers_in_cluster)\n",
    "\n",
    "    # Skip clusters with only 1 node (no edges to draw)\n",
    "    if len(subgraph.nodes) <= 1:\n",
    "        continue\n",
    "\n",
    "    pos = nx.spring_layout(subgraph, seed=42)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    nx.draw(subgraph, pos, with_labels=True,\n",
    "            node_color='lightcoral', edge_color='gray', node_size=800)\n",
    "    plt.title(f\"Louvain Cluster #{cluster_id} ({len(subgraph.nodes)} nodes)\")\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1412ab5-a17c-4406-8145-6800eb2bca4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (peer_tickers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2dcc4e-a0e6-41be-8c66-b5ca2148ebe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "btc_df['return'] = btc_df['close'].pct_change()\n",
    "btc_df['target'] = (btc_df['return'].shift(-1) > 0).astype(int)  # Predict next-day move\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87daa563-fd7d-4c37-9f2d-cdb009f4400a",
   "metadata": {},
   "outputs": [],
   "source": [
    "btc_features = btc_df.set_index('date')[[\n",
    "    'MACD', 'MACD_Diff', 'RSI', 'MFI', 'EMA_Short', 'EMA_Long', \n",
    "    'Bollinger_Upper', 'Bollinger_Lower', 'Stochastic', 'SAR', 'target'\n",
    "]].dropna()\n",
    "\n",
    "final_df = btc_features.join(peer_prices, how='inner')\n",
    "final_df = final_df.dropna()  # Drop rows with any missing peer close prices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce40e8b-79fd-46d6-8b8e-fefc8f1340dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Features and target\n",
    "X = final_df.drop(columns='target')\n",
    "y = final_df['target']\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=False, test_size=0.2)\n",
    "\n",
    "# Pipeline: StandardScaler + RandomForest\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('rf', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# Fit and evaluate\n",
    "pipeline.fit(X_train, y_train)\n",
    "print(\"✅ Model accuracy:\", pipeline.score(X_test, y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91eb8f2e-0914-4af1-a1dd-bd4d59213a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Compute the matrix\n",
    "y_pred = pipeline.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Labels\n",
    "labels = np.array([\n",
    "    [\"TN: Correctly predicted BTC will go down\", \"FP: Predicted up but it went down\"],\n",
    "    [\"FN: Predicted down but it went up\", \"TP: Correctly predicted BTC will go up\"]\n",
    "])\n",
    "\n",
    "# Plot\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Standard numerical matrix\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
    "            xticklabels=[\"Predicted Down\", \"Predicted Up\"],\n",
    "            yticklabels=[\"Actual Down\", \"Actual Up\"],\n",
    "            ax=axes[0])\n",
    "axes[0].set_title(\"Confusion Matrix (Counts)\")\n",
    "axes[0].set_xlabel(\"Prediction\")\n",
    "axes[0].set_ylabel(\"Actual\")\n",
    "\n",
    "# Annotated label version\n",
    "sns.heatmap(cm, annot=labels, fmt='', cmap='Blues', cbar=False,\n",
    "            xticklabels=[\"Predicted Down\", \"Predicted Up\"],\n",
    "            yticklabels=[\"Actual Down\", \"Actual Up\"],\n",
    "            ax=axes[1])\n",
    "axes[1].set_title(\"Confusion Matrix with BTC Prediction Labels\")\n",
    "axes[1].set_xlabel(\"Prediction\")\n",
    "axes[1].set_ylabel(\"Actual\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2fca4b9-7cd7-46f4-b362-36b140faef54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_pred, target_names=[\"Down\", \"Up\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e52d2a-fbe0-4b8b-9c67-5cce735d6b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "# Prep BTC-only dataframe\n",
    "btc_lregression = btc_df.copy()\n",
    "btc_lregression['target'] = btc_lregression['close'].shift(-1)\n",
    "\n",
    "# Keep only TA indicators + target\n",
    "btc_features = btc_lregression.set_index('date')[[\n",
    "    'MACD', 'MACD_Diff', 'RSI', 'MFI', 'EMA_Short', 'EMA_Long',\n",
    "    'Bollinger_Upper', 'Bollinger_Lower', 'Stochastic', 'SAR', 'target'\n",
    "]].dropna()\n",
    "\n",
    "# Join peer prices (cluster tickers)\n",
    "final_lregression = btc_features.join(peer_prices, how='inner').dropna()\n",
    "\n",
    "# Features & Target\n",
    "X = final_lregression.drop(columns='target')\n",
    "y = final_lregression['target']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=False, test_size=0.2)\n",
    "\n",
    "# Build pipeline: Standardization + LinearRegression\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('lr', LinearRegression())\n",
    "])\n",
    "\n",
    "# Train model\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "print(\"✅ R² score:\", r2_score(y_test, y_pred))\n",
    "print(\"📉 RMSE:\", np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc936899-d3ee-4141-9f2d-aba9b979b4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(y_test.index, y_test, label=\"Actual BTC Price\", color='blue')\n",
    "plt.plot(y_test.index, y_pred, label=\"Predicted BTC Price\", color='orange')\n",
    "plt.title(\"BTC Close Price: Actual vs Predicted\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Price (USD)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a70840-636a-4030-a9a0-b40a618da229",
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = y_test - y_pred\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(y_test.index, residuals, label='Residuals (Actual - Predicted)', color='red')\n",
    "plt.axhline(0, linestyle='--', color='gray')\n",
    "plt.title(\"Prediction Residuals\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Error\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47553328-3133-4dc5-84a8-d72e2ae3c2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Residuals\n",
    "residuals = y_test - y_pred\n",
    "\n",
    "# Plot histogram + KDE\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.histplot(residuals, kde=True, bins=40, color='purple')\n",
    "plt.axvline(0, linestyle='--', color='gray')\n",
    "plt.title(\"Distribution of Prediction Residuals\")\n",
    "plt.xlabel(\"Prediction Error (Actual - Predicted)\")\n",
    "plt.ylabel(\"Frequency / Density\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26cb206a-9bb1-4e1f-b1c9-65840f771ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "# Add intercept manually (statsmodels doesn't do it by default)\n",
    "X_sm = sm.add_constant(X)\n",
    "\n",
    "# Fit the model\n",
    "model = sm.OLS(y, X_sm).fit()\n",
    "\n",
    "# Show summary\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227ce317-aef3-408e-8ad0-9a99b756ea2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Select significant features (excluding intercept)\n",
    "significant_features = model.pvalues[model.pvalues < 0.05].index.tolist()\n",
    "X_reduced = X[significant_features[1:]]  # Exclude intercept if present\n",
    "\n",
    "# Build reduced pipeline\n",
    "pipeline_reduced = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('lr', LinearRegression())\n",
    "])\n",
    "\n",
    "# Train model with reduced features\n",
    "pipeline_reduced.fit(X_train[X_reduced.columns], y_train)\n",
    "\n",
    "# Predict with reduced features\n",
    "y_pred_reduced = pipeline_reduced.predict(X_test[X_reduced.columns])\n",
    "\n",
    "# Evaluate\n",
    "print(\"✅ R² score (reduced):\", r2_score(y_test, y_pred_reduced))\n",
    "print(\"📉 RMSE (reduced):\", np.sqrt(mean_squared_error(y_test, y_pred_reduced)))\n",
    "\n",
    "# Residuals\n",
    "residuals = y_test - y_pred_reduced\n",
    "\n",
    "# Plot histogram + KDE\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.histplot(residuals, kde=True, bins=40, color='purple')\n",
    "plt.axvline(0, linestyle='--', color='gray')\n",
    "plt.title(\"Distribution of Prediction Residuals (Reduced Features)\")\n",
    "plt.xlabel(\"Prediction Error (Actual - Predicted)\")\n",
    "plt.ylabel(\"Frequency / Density\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49393f2-54e9-4b47-815c-cfb55bdc4c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals_df = pd.DataFrame({\n",
    "    'Actual': y_test,\n",
    "    'Predicted': y_pred_reduced,\n",
    "    'Residual': residuals\n",
    "})\n",
    "\n",
    "# Filter rows with absolute residual > 7000\n",
    "significant_errors = residuals_df[np.abs(residuals_df['Residual']) > 7000]\n",
    "\n",
    "# Show them\n",
    "print(\"🔍 Residuals with absolute error > $7,000:\")\n",
    "print(significant_errors.sort_values(by='Residual', key=abs, ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c790f6f1-b56b-4efa-9dae-cbebbad5ec7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
